{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DonorsChoose.org Recommender\n",
    "**Author - Rishabh Jain**\n",
    "\n",
    "DonorsChoose.org has funded over 1.1 million classroom requests through the support of 3 million donors, the majority of whom were making their first-ever donation to a public school. If DonorsChoose.org can motivate even a fraction of those donors to make another donation, that could have a huge impact on the number of classroom requests fulfilled. A good solution will enable DonorsChoose.org to build targeted email campaigns recommending specific classroom requests to prior donors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "from scipy import sparse\n",
    "from wordcloud import WordCloud, STOPWORDS \n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "sns.set_style('whitegrid')\n",
    "tqdm_notebook.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to load data : 42.33 seconds\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "donations=pd.read_csv(\"data/Donations.csv\")\n",
    "donors=pd.read_csv(\"data/Donors.csv\")\n",
    "projects=pd.read_csv(\"data/Projects.csv\")\n",
    "schools=pd.read_csv(\"data/Schools.csv\")\n",
    "print(\"Time taken to load data : {:.2f} seconds\".format(time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## DONATIONS\n",
      "----------------------------------------------------------------------\n",
      "Column Name                             Total               Null      \n",
      "----------------------------------------------------------------------\n",
      "Project ID                              4687884             0         \n",
      "Donation ID                             4687884             0         \n",
      "Donor ID                                4687884             0         \n",
      "Donation Included Optional Donation     4687884             0         \n",
      "Donation Amount                         4687884             0         \n",
      "Donor Cart Sequence                     4687884             0         \n",
      "Donation Received Date                  4687884             0         \n",
      "\n",
      "\n",
      "## DONORS\n",
      "----------------------------------------------------------------------\n",
      "Column Name                             Total               Null      \n",
      "----------------------------------------------------------------------\n",
      "Donor ID                                2122640             0         \n",
      "Donor City                              2122640             213097    \n",
      "Donor State                             2122640             0         \n",
      "Donor Is Teacher                        2122640             0         \n",
      "Donor Zip                               2122640             180060    \n",
      "\n",
      "\n",
      "## PROJECTS\n",
      "----------------------------------------------------------------------\n",
      "Column Name                             Total               Null      \n",
      "----------------------------------------------------------------------\n",
      "Project ID                              1110017             0         \n",
      "School ID                               1110017             0         \n",
      "Teacher ID                              1110017             0         \n",
      "Teacher Project Posted Sequence         1110017             0         \n",
      "Project Type                            1110017             0         \n",
      "Project Title                           1110017             6         \n",
      "Project Essay                           1110017             1         \n",
      "Project Short Description               1110017             3         \n",
      "Project Need Statement                  1110017             3         \n",
      "Project Subject Category Tree           1110017             29        \n",
      "Project Subject Subcategory Tree        1110017             29        \n",
      "Project Grade Level Category            1110017             0         \n",
      "Project Resource Category               1110017             36        \n",
      "Project Cost                            1110017             0         \n",
      "Project Posted Date                     1110017             0         \n",
      "Project Expiration Date                 1110017             14        \n",
      "Project Current Status                  1110017             0         \n",
      "Project Fully Funded Date               1110017             283253    \n",
      "\n",
      "\n",
      "## SCHOOLS\n",
      "----------------------------------------------------------------------\n",
      "Column Name                             Total               Null      \n",
      "----------------------------------------------------------------------\n",
      "School ID                               72993               0         \n",
      "School Name                             72993               0         \n",
      "School Metro Type                       72993               0         \n",
      "School Percentage Free Lunch            72993               1141      \n",
      "School State                            72993               0         \n",
      "School Zip                              72993               0         \n",
      "School City                             72993               227       \n",
      "School County                           72993               2         \n",
      "School District                         72993               0         \n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs={\n",
    "    \"donations\":donations,\n",
    "    \"donors\":donors,\n",
    "    \"projects\":projects,\n",
    "    \"schools\":schools\n",
    "}\n",
    "\n",
    "for name,df in dfs.items():\n",
    "    columns=df.columns\n",
    "    print(\"\\n## \"+name.upper())\n",
    "    print('-'*70)\n",
    "    print('{0}{1}{2}'.format(\"Column Name\".ljust(40),\"Total\".ljust(20),\"Null\".ljust(10)))\n",
    "    print('-'*70)\n",
    "    for column in columns:\n",
    "        total=str(df[column].shape[0])\n",
    "        nulls=str(df[column].isnull().sum())\n",
    "        print('{0}{1}{2}'.format(column.ljust(40),total.ljust(20),nulls.ljust(10)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling for Proof-of-Concept\n",
    "For POC, we are choosing a small subset from the entire dataset. This way we will be able to train, validate and test the models really fast. It is recommended to use the entire dataset for training while deploying in production for better recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donations shape\t\t(200000, 7)\n",
      "Projects shape\t\t(158066, 18)\n"
     ]
    }
   ],
   "source": [
    "dataset_size=200000\n",
    "donations=donations.sample(n=dataset_size,random_state=42)\n",
    "donors=donors[donors['Donor ID'].isin(donations['Donor ID'])]\n",
    "projects=projects[projects['Project ID'].isin(donations['Project ID'])]\n",
    "print('Donations shape\\t\\t{}'.format(donations.shape))\n",
    "print('Projects shape\\t\\t{}'.format(projects.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging datasets\n",
    "- Left join on `projects` and `schools`\n",
    "- Left join on `donations` and `donors`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "projects=pd.merge(projects,schools,on='School ID',how='left')\n",
    "donations=pd.merge(donations,donors[['Donor ID','Donor Is Teacher']],on='Donor ID',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering donations by donor who are not teacher\n",
    "Our recommendation engine should be recommending donors who are not teachers. This is why we should supply only those donations for training model where donor is not a teacher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Donor Is Teacher</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>142507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>57237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   count\n",
       "Donor Is Teacher        \n",
       "No                142507\n",
       "Yes                57237"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "donations.groupby('Donor Is Teacher').size().to_frame(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donations shape\t\t(142507, 8)\n",
      "Projects shape\t\t(120697, 26)\n"
     ]
    }
   ],
   "source": [
    "donations=donations[donations['Donor Is Teacher']=='No']\n",
    "projects=projects[projects['Project ID'].isin(donations['Project ID'])]\n",
    "print('Donations shape\\t\\t{}'.format(donations.shape))\n",
    "print('Projects shape\\t\\t{}'.format(projects.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminating Projects with no information\n",
    "Before we move further, we should check if all the `Project ID` in **donations** dataset are present in **projects** dataset. Such difference from both the sets should be removed from the **donations** dataset, because we cannot trace back the project details to build a donor profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donations shape\t\t(140708, 8)\n",
      "Projects shape\t\t(120697, 26)\n"
     ]
    }
   ],
   "source": [
    "common_project_ids=list(set(donations[\"Project ID\"]).intersection(set(projects[\"Project ID\"])))\n",
    "donations=donations[donations[\"Project ID\"].isin(common_project_ids)]\n",
    "projects=projects[projects[\"Project ID\"].isin(common_project_ids)]\n",
    "print('Donations shape\\t\\t{}'.format(donations.shape))\n",
    "print('Projects shape\\t\\t{}'.format(projects.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting new indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "donors=donors.set_index('Donor ID')\n",
    "projects=projects.set_index('Project ID')\n",
    "donations=donations.set_index(['Donor ID','Project ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique (Donor,Project) Transformation & Log Transformation\n",
    "Here, we will aggregate the donations where a single donor donated to same project more than once. Such donations will grouped by `Donor ID` and `Project ID`, and `Donation Amount` will be summed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "625f158fac4343459821d03d0c6b3176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=139564.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Log Amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Donor ID</th>\n",
       "      <th>Project ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00000ce845c00cbf0686c992fc369df4</th>\n",
       "      <th>5bab6101eed588c396a59f6bd64274b6</th>\n",
       "      <td>3.931826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00005454366b6b914f9a8290f18f4aed</th>\n",
       "      <th>d82a6d8c82ca51cc1a7bd54bad289169</th>\n",
       "      <td>4.615121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000a2175753bc165e53c408589a3bd6</th>\n",
       "      <th>2fc5b57c1a29c7489b182e8c49c0621b</th>\n",
       "      <td>3.258097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000d299ce46c8375f29f7bb792b9eae</th>\n",
       "      <th>45023d76c4a80d90f0f60a80d5a76c9f</th>\n",
       "      <td>3.258097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001107b9faa5c3bb42cfcecece1d587</th>\n",
       "      <th>1d478d72cda77d1cbe8479ea26130590</th>\n",
       "      <td>2.397895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   Log Amount\n",
       "Donor ID                         Project ID                                  \n",
       "00000ce845c00cbf0686c992fc369df4 5bab6101eed588c396a59f6bd64274b6    3.931826\n",
       "00005454366b6b914f9a8290f18f4aed d82a6d8c82ca51cc1a7bd54bad289169    4.615121\n",
       "0000a2175753bc165e53c408589a3bd6 2fc5b57c1a29c7489b182e8c49c0621b    3.258097\n",
       "0000d299ce46c8375f29f7bb792b9eae 45023d76c4a80d90f0f60a80d5a76c9f    3.258097\n",
       "0001107b9faa5c3bb42cfcecece1d587 1d478d72cda77d1cbe8479ea26130590    2.397895"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def log_transformation(x):\n",
    "    return np.log(x+1)\n",
    "\n",
    "donations['Log Amount']=donations['Donation Amount']\n",
    "donations=donations.groupby(level=['Donor ID','Project ID'])['Log Amount']\\\n",
    "    .sum()\\\n",
    "    .progress_apply(log_transformation).to_frame()\n",
    "donations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# OF DONORS\t118036\n",
      "# OF PROJECTS\t120697\n"
     ]
    }
   ],
   "source": [
    "print(\"# OF DONORS\\t{}\".format(\n",
    "    donations.index.get_level_values('Donor ID').unique().shape[0])\n",
    ")\n",
    "print(\"# OF PROJECTS\\t{}\".format(\n",
    "    donations.index.get_level_values('Project ID').unique().shape[0])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train & test split\n",
    "Here, the test set will only contain the donations that has donors present in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donations Train Shape\t(111651, 1)\n",
      "Donations Test Shape\t(5475, 1)\n"
     ]
    }
   ],
   "source": [
    "donations_train,donations_test=train_test_split(donations,test_size=0.2,random_state=42)\n",
    "donor_train_ids=donations_train.index.get_level_values(0)\n",
    "donations_test=donations_test[donations_test.index.get_level_values(0).isin(donor_train_ids)]\n",
    "print('Donations Train Shape\\t{}'.format(donations_train.shape))\n",
    "print('Donations Test Shape\\t{}'.format(donations_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projects Train Shape\t(99134, 25)\n",
      "Projects Test Shape\t(5421, 25)\n"
     ]
    }
   ],
   "source": [
    "project_train_ids=donations_train.index.get_level_values(1).unique()\n",
    "project_test_ids=donations_test.index.get_level_values(1).unique()\n",
    "projects_train= projects.loc[project_train_ids]\n",
    "projects_test = projects.loc[project_test_ids]\n",
    "print('Projects Train Shape\\t{}'.format(projects_train.shape))\n",
    "print('Projects Test Shape\\t{}'.format(projects_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Recommendation Engine\n",
    "We will try three approaches for building a recommendation engine :\n",
    "- **Content based filtering**\n",
    "- **Attribute based clustering**\n",
    "- **Collaborative filtering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Content based filtering\n",
    "In this approach, we will recommend the list of donors for a new project based on the project similarity between the new project and the existing projects serveral donors has donated to. Here the project similarity is identified by the taking lookig at the content of `Project Title` and `Project Essay`.\n",
    "\n",
    "**Training Steps :**\n",
    "- First we will develop a vocabulary from all the existing projects.\n",
    "- Then we will represent each project with a vector of numbers. Index of each number in this vector will represent the presence of that word from vocbulary. This will be done using TF-IDF vectorizer. We will call such vector *Project Profile* ($PP$).\n",
    "- Next we will build the donor profile ($DP$) based on the projects donor has donated to. This will be done by calculating the weighted average of project profiles and the log of their donation amounts ($DA$).\n",
    "\n",
    "$$DP=\\frac{PP_1\\times log(DA_1)+PP_2\\times log(DA_2)+...+PP_n\\times log(DA_n)}{log(DA_1)+log(DA_2)+...+log(DA_n)}$$\n",
    "\n",
    "**Note:** All the donors profiles can then be stored as a pickle for making prediction.\n",
    "\n",
    "**Predicting Steps :**\n",
    "- In order to recommend the list of most relevant donors for a new project, we will first create its project profile using the same vocabulary.\n",
    "- And then we will find the cosine similarity between the new project profile and all the donor profiles. This will be a vectorized implmentation otherwise recommendation will take too long.\n",
    "- From the second step, we will get a list of similarity scores between the new project and the project interests of all the donors.\n",
    "- We will then simply choose the top N donors with high similarity score.\n",
    "\n",
    "### Merging Project and School dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_to_consider=[\n",
    "    \"Project Title\",\n",
    "    \"Project Essay\",\n",
    "    \"Project Subject Category Tree\",\n",
    "    \"Project Need Statement\",\n",
    "    \"Project Resource Category\",\n",
    "    \"School Metro Type\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tfid_vector from pickle file if exist\n",
    "directory=\"./features/\"\n",
    "vectorizer_filepath=directory+\"tfidf_vectorizer.pickle\"\n",
    "tfidf_matrix_filepath=directory+\"tfidf_matrix.pickle\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "if os.path.isfile(vectorizer_filepath) and os.path.isfile(tfidf_matrix_filepath):\n",
    "    vectorizer=pickle.load(open(vectorizer_filepath,\"rb\"))\n",
    "    tfidf_matrix=pickle.load(open(tfidf_matrix_filepath,\"rb\"))\n",
    "else:\n",
    "    # Creating a vocabulary\n",
    "    text_corpus=''\n",
    "    for attribute in attributes_to_consider:\n",
    "        projects_train[attribute]=projects_train[attribute].astype(str)\n",
    "        projects_train[attribute].fillna('',inplace=True)\n",
    "        text_corpus+=' '+projects_train[attribute]    \n",
    "    # Vectorizing the vocabulary\n",
    "    start=time.time()\n",
    "    vectorizer=TfidfVectorizer(\n",
    "        strip_accents='unicode',\n",
    "        analyzer='word',\n",
    "        lowercase=True,\n",
    "        stop_words='english',\n",
    "        max_df=0.9,\n",
    "        token_pattern=r'(?u)\\b[A-Za-z]+\\b'\n",
    "    )\n",
    "    tfidf_matrix=vectorizer.fit_transform(text_corpus)\n",
    "    pickle.dump(vectorizer,open(vectorizer_filepath,\"wb\"))\n",
    "    pickle.dump(tfidf_matrix,open(tfidf_matrix_filepath,\"wb\"))\n",
    "    print(\"Time taken to apply TFID on text corpus : {:.2f} seconds\".format(time.time()-start))\n",
    "\n",
    "feature_names=vectorizer.get_feature_names()\n",
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects_train_ids=projects_train.index.unique()\n",
    "\n",
    "def get_project_profile(project_id):\n",
    "    '''Returns the tfidf vector for the given project ID'''\n",
    "    idx=projects_train_ids.tolist().index(project_id)\n",
    "    project_profile=tfidf_matrix[idx:idx+1]\n",
    "    return project_profile\n",
    "\n",
    "def get_project_profiles(project_ids):\n",
    "    '''Returns the tfidf sparse vectors for the given project IDs'''\n",
    "    project_profiles=[get_project_profile(project_id) for project_id in np.ravel([project_ids])]\n",
    "    project_profiles=sparse.vstack(project_profiles)\n",
    "    return project_profiles\n",
    "\n",
    "def get_donor_profile(df,donor_id):\n",
    "    project_ids=df.index.values\n",
    "    log_amounts=df.values\n",
    "    project_profiles=get_project_profiles(project_ids)\n",
    "    donor_profile=np.sum(project_profiles.multiply(log_amounts),axis=0)/(np.sum(log_amounts)+1)\n",
    "    donor_profile=sparse.csr_matrix(normalize(donor_profile))\n",
    "    return donor_profile\n",
    "\n",
    "def get_donor_profiles(df):\n",
    "    '''\n",
    "    Returns the tfidf vectors for the given donor IDs\n",
    "    This function will take some time. While converting\n",
    "    this notebok to python script, its better to use \n",
    "    multiprocessing for this function.\n",
    "    '''\n",
    "    donor_ids=df.index.get_level_values(level='Donor ID').unique()\n",
    "    donor_profiles=[\n",
    "        get_donor_profile(df.loc[donor_id],donor_id) for donor_id in tqdm_notebook(donor_ids)\n",
    "    ]\n",
    "    donor_profiles=sparse.vstack(donor_profiles)\n",
    "    return donor_ids,donor_profiles\n",
    "    \n",
    "def train_model(df,save_model=True):\n",
    "    '''\n",
    "    Trains the model for {num_donors} donors and \n",
    "    saves the tuple (donor_profiles,donor_ids) \n",
    "    into a same pickle file.\n",
    "    '''\n",
    "    directory='./models/'\n",
    "    num_donors=len(df.index.get_level_values(0).unique())\n",
    "    model_filepath=directory+'donor_profiles.pickle'\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)    \n",
    "    if os.path.isfile(model_filepath):\n",
    "        donor_ids,donor_profiles=pickle.load(open(model_filepath,\"rb\"))\n",
    "        print('Profiles for {} donors loaded!'.format(len(donor_ids)))\n",
    "    else:\n",
    "        print('Building profiles for {} donors...'.format(num_donors))\n",
    "        donor_ids,donor_profiles=get_donor_profiles(df)\n",
    "        pickle.dump((donor_ids,donor_profiles),open(model_filepath,\"wb\"))\n",
    "    return (donor_ids,donor_profiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "Let's take a look at few of donor profiles which based on their past donations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "donor_ids,donor_profiles=train_model(donations_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Donor Profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_donors_interest(donor_id,top_n=10):\n",
    "    index=list(donor_ids).index(donor_id)\n",
    "    tfidf_vector=donor_profiles[index]\n",
    "    tfidf_vector=tfidf_vector.toarray().reshape(-1)\n",
    "    donor_interests=pd.DataFrame(\n",
    "        zip(feature_names,tfidf_vector),\n",
    "        columns=['Token','Relevance']\n",
    "    ).sort_values(by='Relevance',ascending=False)\n",
    "    return donor_interests.head(top_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample Donor Profile 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_donors_interest(np.random.choice(donor_ids,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample Donor Profile 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_donors_interest(np.random.choice(donor_ids,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_donors(project,cut_off_percentile=99.9,plot=False):\n",
    "    '''\n",
    "    Returns the list of Donor IDs whose similarity score is \n",
    "    greater than {score_threshold} defind. Similarity score\n",
    "    range is greater than 0 and less than 1.\n",
    "    '''\n",
    "    start=time.time()\n",
    "    text=''\n",
    "    for attribute in attributes_to_consider:\n",
    "        value=project[attribute].values[0]\n",
    "        value='' if type(value)==float else value\n",
    "        text+=value\n",
    "    project_profile=normalize(vectorizer.transform([text]))\n",
    "    similarity_scores=cosine_similarity(project_profile,donor_profiles).reshape(-1).astype(np.object)\n",
    "    recommended_donors=np.column_stack((donor_ids,similarity_scores))\n",
    "    cut_off=np.percentile(similarity_scores,cut_off_percentile)\n",
    "    recommended_donors=recommended_donors[recommended_donors[:,1]>cut_off]\n",
    "    recommended_donors=recommended_donors[recommended_donors[:,1].argsort()[::-1]]\n",
    "    end=time.time()\n",
    "    if plot:\n",
    "        print('Time taken to recommend donors : {:.2f} seconds'.format(end-start))\n",
    "        print('Score cut-off : {}'.format(cut_off))\n",
    "        print('Project ID : {}'.format(project.index[0]))\n",
    "        ax=sns.distplot(similarity_scores,kde=False,color='red',rug=True)\n",
    "        ax.set(xlabel='Similarity Score', ylabel='# of Donors')\n",
    "    return recommended_donors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recommendation on projects the recommender was trained on!\n",
    "Here the defualt `cut_off` of **0.70** is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "index=np.random.choice(range(projects_train.shape[0]),size=1)[0]\n",
    "project=projects_train.iloc[index:index+1]\n",
    "recommended_donors=recommend_donors(\n",
    "    project,\n",
    "    cut_off_percentile=99.999,\n",
    "    plot=True\n",
    ")\n",
    "recommended_donors=pd.DataFrame(\n",
    "    recommended_donors,\n",
    "    columns=['Donor ID','Score']\n",
    ")\n",
    "print('-'*100)\n",
    "print('ACTUAL DONORS :')\n",
    "actual_donors=donors[donors['Donor ID'].isin(donations_train.xs(project.index[0],level=1).index.values)]\n",
    "actual_donors=pd.merge(actual_donors['Donor ID'],recommended_donors,on='Donor ID',how='left')\n",
    "actual_donors=pd.merge(actual_donors,donors,on='Donor ID',how='left')\n",
    "print(actual_donors)\n",
    "print('-'*100)\n",
    "print('RECOMMENDED DONORS :')\n",
    "recommended_donors=pd.merge(recommended_donors,donors,on='Donor ID',how='left')\n",
    "print(recommended_donors.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recommendation on projects NOT trained on!\n",
    "Here the `score_threshold` of around 0.5 is used. The reason why we are using a lower `score_threshold` is because we have trained on a smaller training set. So recommedation engine has seen very less number of projects and might not be able to give similarity score greater than 0.7 for every new project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "index=np.random.choice(range(projects_test.shape[0]),size=1)[0]\n",
    "project=projects_test.iloc[index:index+1]\n",
    "recommended_donors=recommend_donors(\n",
    "    project,\n",
    "    cut_off_percentile=99.99,\n",
    "    plot=True\n",
    ")\n",
    "recommended_donors=pd.DataFrame(\n",
    "    recommended_donors,\n",
    "    columns=['Donor ID','Score']\n",
    ")\n",
    "print('-'*100)\n",
    "print('ACTUAL DONORS :')\n",
    "actual_donors=donors[donors['Donor ID'].isin(donations_test.xs(project.index[0],level=1).index.values)]\n",
    "actual_donors=pd.merge(actual_donors['Donor ID'],recommended_donors,on='Donor ID',how='left')\n",
    "actual_donors=pd.merge(actual_donors,donors,on='Donor ID',how='left')\n",
    "print(actual_donors)\n",
    "print('-'*100)\n",
    "print('RECOMMENDED DONORS :')\n",
    "recommended_donors=pd.merge(recommended_donors,donors,on='Donor ID',how='left')\n",
    "print(recommended_donors.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating\n",
    "In this section, we will calculate\n",
    "- **Precision@k**\n",
    "$$\n",
    "\\boxed{\n",
    "\\text{Precision@k}=\\frac\n",
    "{\\text{# of recommended donors @k that are relevant}}\n",
    "{\\text{# of recommended donors @k}}\n",
    "}\n",
    "$$\n",
    "- **Recall@k**\n",
    "$$\n",
    "\\boxed{\n",
    "\\text{Recall@k}=\\frac\n",
    "{\\text{# of recommended donors @k that are relevant}}\n",
    "{\\text{Total # of relevant donors}}\n",
    "}\n",
    "$$\n",
    "\n",
    "for projects which are\n",
    "- part of the training set.\n",
    "- new to the recommendation engine. Here we will only use those donors as the recommended donors for which our recommendation engine has those profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_K(donations,projects,K,cut_off_percentile=99.99):\n",
    "    accuracy={\n",
    "        \"precision\":{},\n",
    "        \"recall\":{},\n",
    "        \"f1\":{}\n",
    "    }\n",
    "    print('Evaluating the model...')\n",
    "    for i in tqdm_notebook(range(projects.shape[0])):\n",
    "        project=projects.iloc[i:i+1]\n",
    "        project_id=project.index.values[0]\n",
    "        relevant=donations.xs(project_id,level=1).index.values\n",
    "        recommended=recommend_donors(project,cut_off_percentile)[:,0]\n",
    "        for k in K:\n",
    "            recommended_k=recommended[:k]\n",
    "            recommneded_relevant_k=list(set(recommended_k).intersection(set(relevant)))\n",
    "            # Precision\n",
    "            if len(recommended_k)==0 and len(relevant)==0:\n",
    "                precision=1\n",
    "            elif len(recommended_k)==0 and len(relevant)!=0:\n",
    "                precision=0\n",
    "            else:\n",
    "                precision=len(recommneded_relevant_k)/len(recommended_k)\n",
    "            if accuracy['precision'].get(k,None)==None:\n",
    "                  accuracy['precision'][k]=[]\n",
    "            accuracy['precision'][k].append(precision)\n",
    "            # Recall\n",
    "            if len(relevant)==0 and len(recommended_k)==0:\n",
    "                recall=1\n",
    "            elif len(relevant)==0 and len(recommended_k)!=0:\n",
    "                recall=0\n",
    "            else:\n",
    "                recall=len(recommneded_relevant_k)/len(relevant)\n",
    "            if accuracy['recall'].get(k,None)==None:\n",
    "                  accuracy['recall'][k]=[]\n",
    "            accuracy['recall'][k].append(recall)\n",
    "            # f1 score\n",
    "            if precision==0 and recall==0:\n",
    "                f1=0\n",
    "            else:\n",
    "                f1=(2*precision*recall)/(precision+recall)\n",
    "            if accuracy['f1'].get(k,None)==None:\n",
    "                accuracy['f1'][k]=[]\n",
    "            accuracy['f1'][k].append(f1)\n",
    "    for k in K:\n",
    "        accuracy['precision'][k]=np.mean(accuracy['precision'][k])\n",
    "        accuracy['recall'][k]=np.mean(accuracy['recall'][k])\n",
    "        accuracy['f1'][k]=np.mean(accuracy['f1'][k])\n",
    "    accuracy=pd.DataFrame({\n",
    "        \"k\":K,\n",
    "        \"precision\":list(accuracy['precision'].values()),\n",
    "        \"recall\":list(accuracy['recall'].values()),\n",
    "        \"f1\":list(accuracy['f1'].values())\n",
    "    })\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_sample_size=5000\n",
    "K=[5,10,20,50,100,500,1000,2000]\n",
    "accuracy=precision_recall_K(\n",
    "    donations_train,\n",
    "    projects_train.sample(n=train_sample_size,random_state=42),\n",
    "    K,cut_off_percentile=99.999\n",
    ")\n",
    "# Plotting accuracy\n",
    "plt=sns.lineplot(x='k',y='value',hue='variable',data=pd.melt(accuracy,['k']));\n",
    "fig=plt.get_figure()\n",
    "fig.savefig('images/train_accuracy_{}_{}.png'.format(len(donor_ids),train_sample_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_sample_size=5000\n",
    "K=[5,10,20,50,100,500,1000,2000]\n",
    "accuracy=precision_recall_K(\n",
    "    donations_test,\n",
    "    projects_test.sample(n=test_sample_size,random_state=42),\n",
    "    K,cut_off_percentile=99\n",
    ")\n",
    "# Plotting accuracy\n",
    "plt=sns.lineplot(x='k',y='value',hue='variable',data=pd.melt(accuracy,['k']));\n",
    "fig=plt.get_figure()\n",
    "fig.savefig('images/test_accuracy_{}_{}.png'.format(len(donor_ids),test_sample_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
