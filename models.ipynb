{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DonorsChoose.org Recommender\n",
    "**Author - Rishabh Jain**\n",
    "\n",
    "DonorsChoose.org has funded over 1.1 million classroom requests through the support of 3 million donors, the majority of whom were making their first-ever donation to a public school. If DonorsChoose.org can motivate even a fraction of those donors to make another donation, that could have a huge impact on the number of classroom requests fulfilled. A good solution will enable DonorsChoose.org to build targeted email campaigns recommending specific classroom requests to prior donors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "from scipy import sparse\n",
    "from wordcloud import WordCloud, STOPWORDS \n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "sns.set_style('whitegrid')\n",
    "tqdm_notebook.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to load data : 46.22 seconds\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "donations=pd.read_csv(\"data/Donations.csv\")\n",
    "donors=pd.read_csv(\"data/Donors.csv\")\n",
    "projects=pd.read_csv(\"data/Projects.csv\")\n",
    "schools=pd.read_csv(\"data/Schools.csv\")\n",
    "print(\"Time taken to load data : {:.2f} seconds\".format(time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## DONATIONS\n",
      "----------------------------------------------------------------------\n",
      "Column Name                             Total               Null      \n",
      "----------------------------------------------------------------------\n",
      "Project ID                              4687884             0         \n",
      "Donation ID                             4687884             0         \n",
      "Donor ID                                4687884             0         \n",
      "Donation Included Optional Donation     4687884             0         \n",
      "Donation Amount                         4687884             0         \n",
      "Donor Cart Sequence                     4687884             0         \n",
      "Donation Received Date                  4687884             0         \n",
      "\n",
      "\n",
      "## DONORS\n",
      "----------------------------------------------------------------------\n",
      "Column Name                             Total               Null      \n",
      "----------------------------------------------------------------------\n",
      "Donor ID                                2122640             0         \n",
      "Donor City                              2122640             213097    \n",
      "Donor State                             2122640             0         \n",
      "Donor Is Teacher                        2122640             0         \n",
      "Donor Zip                               2122640             180060    \n",
      "\n",
      "\n",
      "## PROJECTS\n",
      "----------------------------------------------------------------------\n",
      "Column Name                             Total               Null      \n",
      "----------------------------------------------------------------------\n",
      "Project ID                              1110017             0         \n",
      "School ID                               1110017             0         \n",
      "Teacher ID                              1110017             0         \n",
      "Teacher Project Posted Sequence         1110017             0         \n",
      "Project Type                            1110017             0         \n",
      "Project Title                           1110017             6         \n",
      "Project Essay                           1110017             1         \n",
      "Project Short Description               1110017             3         \n",
      "Project Need Statement                  1110017             3         \n",
      "Project Subject Category Tree           1110017             29        \n",
      "Project Subject Subcategory Tree        1110017             29        \n",
      "Project Grade Level Category            1110017             0         \n",
      "Project Resource Category               1110017             36        \n",
      "Project Cost                            1110017             0         \n",
      "Project Posted Date                     1110017             0         \n",
      "Project Expiration Date                 1110017             14        \n",
      "Project Current Status                  1110017             0         \n",
      "Project Fully Funded Date               1110017             283253    \n",
      "\n",
      "\n",
      "## SCHOOLS\n",
      "----------------------------------------------------------------------\n",
      "Column Name                             Total               Null      \n",
      "----------------------------------------------------------------------\n",
      "School ID                               72993               0         \n",
      "School Name                             72993               0         \n",
      "School Metro Type                       72993               0         \n",
      "School Percentage Free Lunch            72993               1141      \n",
      "School State                            72993               0         \n",
      "School Zip                              72993               0         \n",
      "School City                             72993               227       \n",
      "School County                           72993               2         \n",
      "School District                         72993               0         \n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs={\n",
    "    \"donations\":donations,\n",
    "    \"donors\":donors,\n",
    "    \"projects\":projects,\n",
    "    \"schools\":schools\n",
    "}\n",
    "\n",
    "for name,df in dfs.items():\n",
    "    columns=df.columns\n",
    "    print(\"\\n## \"+name.upper())\n",
    "    print('-'*70)\n",
    "    print('{0}{1}{2}'.format(\"Column Name\".ljust(40),\"Total\".ljust(20),\"Null\".ljust(10)))\n",
    "    print('-'*70)\n",
    "    for column in columns:\n",
    "        total=str(df[column].shape[0])\n",
    "        nulls=str(df[column].isnull().sum())\n",
    "        print('{0}{1}{2}'.format(column.ljust(40),total.ljust(20),nulls.ljust(10)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling for Proof-of-Concept\n",
    "For POC, we are choosing a small subset from the entire dataset. This way we will be able to train, validate and test the models really fast. It is recommended to use the entire dataset for training while deploying in production for better recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donations shape\t\t(50000, 7)\n",
      "Projects shape\t\t(45863, 18)\n"
     ]
    }
   ],
   "source": [
    "dataset_size=50000\n",
    "donations=donations.sample(n=dataset_size,random_state=42)\n",
    "donors=donors[donors['Donor ID'].isin(donations['Donor ID'])]\n",
    "projects=projects[projects['Project ID'].isin(donations['Project ID'])]\n",
    "print('Donations shape\\t\\t{}'.format(donations.shape))\n",
    "print('Projects shape\\t\\t{}'.format(projects.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging datasets\n",
    "- Left join on `projects` and `schools`\n",
    "- Left join on `donations` and `donors`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "projects=pd.merge(projects,schools,on='School ID',how='left')\n",
    "donations=pd.merge(donations,donors[['Donor ID','Donor Is Teacher']],on='Donor ID',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering donations by donor who are not teacher\n",
    "Our recommendation engine should be recommending donors who are not teachers. This is why we should supply only those donations for training model where donor is not a teacher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Donor Is Teacher</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>35604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>14343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  count\n",
       "Donor Is Teacher       \n",
       "No                35604\n",
       "Yes               14343"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "donations.groupby('Donor Is Teacher').size().to_frame(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donations shape\t\t(35604, 8)\n",
      "Projects shape\t\t(33586, 26)\n"
     ]
    }
   ],
   "source": [
    "donations=donations[donations['Donor Is Teacher']=='No']\n",
    "projects=projects[projects['Project ID'].isin(donations['Project ID'])]\n",
    "print('Donations shape\\t\\t{}'.format(donations.shape))\n",
    "print('Projects shape\\t\\t{}'.format(projects.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminating Projects with no information\n",
    "Before we move further, we should check if all the `Project ID` in **donations** dataset are present in **projects** dataset. Such difference from both the sets should be removed from the **donations** dataset, because we cannot trace back the project details to build a donor profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donations shape\t\t(35136, 8)\n",
      "Projects shape\t\t(33586, 26)\n"
     ]
    }
   ],
   "source": [
    "common_project_ids=list(set(donations[\"Project ID\"]).intersection(set(projects[\"Project ID\"])))\n",
    "donations=donations[donations[\"Project ID\"].isin(common_project_ids)]\n",
    "projects=projects[projects[\"Project ID\"].isin(common_project_ids)]\n",
    "print('Donations shape\\t\\t{}'.format(donations.shape))\n",
    "print('Projects shape\\t\\t{}'.format(projects.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting new indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "donors=donors.set_index('Donor ID')\n",
    "projects=projects.set_index('Project ID')\n",
    "donations=donations.set_index(['Donor ID','Project ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique (Donor,Project) Transformation & Log Transformation\n",
    "Here, we will aggregate the donations where a single donor donated to same project more than once. Such donations will grouped by `Donor ID` and `Project ID`, and `Donation Amount` will be summed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af083ff925aa490cbcce2a6d8512f835",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=34994.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Log Amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Donor ID</th>\n",
       "      <th>Project ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0000a2175753bc165e53c408589a3bd6</th>\n",
       "      <th>2fc5b57c1a29c7489b182e8c49c0621b</th>\n",
       "      <td>3.258097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00014d846426ac502c555c2c28a0ef63</th>\n",
       "      <th>f80a019ef864b2778c599c2a3b106c81</th>\n",
       "      <td>5.525453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00024e86676fc2c3b317e0166ffa4768</th>\n",
       "      <th>c9febf1ce32e316a6c3f58438b567333</th>\n",
       "      <td>3.931826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0002b674d10ab80873a6665b0e472dce</th>\n",
       "      <th>d94fdd5242f3dbd1952bb08fec48c6f4</th>\n",
       "      <td>2.397895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0005217360eaad75db1d28837bd15658</th>\n",
       "      <th>59ee35cef81b61bd8eea56cef5570318</th>\n",
       "      <td>4.615121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   Log Amount\n",
       "Donor ID                         Project ID                                  \n",
       "0000a2175753bc165e53c408589a3bd6 2fc5b57c1a29c7489b182e8c49c0621b    3.258097\n",
       "00014d846426ac502c555c2c28a0ef63 f80a019ef864b2778c599c2a3b106c81    5.525453\n",
       "00024e86676fc2c3b317e0166ffa4768 c9febf1ce32e316a6c3f58438b567333    3.931826\n",
       "0002b674d10ab80873a6665b0e472dce d94fdd5242f3dbd1952bb08fec48c6f4    2.397895\n",
       "0005217360eaad75db1d28837bd15658 59ee35cef81b61bd8eea56cef5570318    4.615121"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def log_transformation(x):\n",
    "    return np.log(x+1)\n",
    "\n",
    "donations['Log Amount']=donations['Donation Amount']\n",
    "donations=donations.groupby(level=['Donor ID','Project ID'])['Log Amount']\\\n",
    "    .sum()\\\n",
    "    .progress_apply(log_transformation).to_frame()\n",
    "donations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# OF DONORS\t31928\n",
      "# OF PROJECTS\t33586\n"
     ]
    }
   ],
   "source": [
    "print(\"# OF DONORS\\t{}\".format(\n",
    "    donations.index.get_level_values('Donor ID').unique().shape[0])\n",
    ")\n",
    "print(\"# OF PROJECTS\\t{}\".format(\n",
    "    donations.index.get_level_values('Project ID').unique().shape[0])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train & test split\n",
    "Here, the test set will only contain the donations that has donors present in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donations Train Shape\t(27995, 1)\n",
      "Donations Test Shape\t(807, 1)\n"
     ]
    }
   ],
   "source": [
    "donations_train,donations_test=train_test_split(donations,test_size=0.2,random_state=42)\n",
    "donor_train_ids=donations_train.index.get_level_values(0)\n",
    "donations_test=donations_test[donations_test.index.get_level_values(0).isin(donor_train_ids)]\n",
    "print('Donations Train Shape\\t{}'.format(donations_train.shape))\n",
    "print('Donations Test Shape\\t{}'.format(donations_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projects Train Shape\t(27088, 25)\n",
      "Projects Test Shape\t(807, 25)\n"
     ]
    }
   ],
   "source": [
    "project_train_ids=donations_train.index.get_level_values(1).unique()\n",
    "project_test_ids=donations_test.index.get_level_values(1).unique()\n",
    "projects_train= projects.loc[project_train_ids]\n",
    "projects_test = projects.loc[project_test_ids]\n",
    "print('Projects Train Shape\\t{}'.format(projects_train.shape))\n",
    "print('Projects Test Shape\\t{}'.format(projects_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Recommendation Engine\n",
    "We will try two main approaches for building a recommendation engine :\n",
    "1. Content based filtering\n",
    "2. Collaborative filtering\n",
    "\n",
    "### Content based filtering\n",
    "In this approach, we will recommend the list of donors for a new project based on the project similarity between the new project and the existing projects serveral donors has donated to in the past. Here the project similarity is identified by the taking a look at the content of project attributes like :\n",
    "- Project Title\n",
    "- Project Essay\n",
    "- Project Need Statement\n",
    "\n",
    "#### Training Steps\n",
    "1. First, we will develop a vocabulary from all the existing projects.\n",
    "2. Then we will represent each project with a vector of numbers. Index of each number in this vector will represent the presence of that word from vocbulary. This will be done using [TF-IDF](http://www.tfidf.com/) vectorizer. We will call such vector ***Project Profile*** ($PP$).\n",
    "3. Next, we will build the ***Donor Profile*** ($DP$) based on the projects donor has donated to. This will be done by calculating the weighted average of project profiles and the log of their donation amounts ($DA$).\n",
    "\n",
    "$$DP=\\frac{PP_1\\times log(DA_1)+PP_2\\times log(DA_2)+...+PP_n\\times log(DA_n)}{log(DA_1)+log(DA_2)+...+log(DA_n)}$$\n",
    "\n",
    "4. Finally, all the donors profiles will then be stored as a pickle file for making prediction.\n",
    "\n",
    "#### Predicting Steps\n",
    "1. In order to recommend the list of most relevant donors for a new project, we will first create its project profile using the same vocabulary.\n",
    "2. And then we will find the cosine similarity between the new project profile and all the donor profiles stored. This will be a vectorized implmentation otherwise recommendation will take way too long.\n",
    "3. From the second step, we will get a list of similarity scores between the new project and the project interests of all the donors.\n",
    "4. We will then simply choose the top N donors with high similarity score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentBasedRecommender:\n",
    "\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        projects: Dataframe indexed by project ID\n",
    "        donations: Dataframe indexed by donor ID & project ID\n",
    "        '''\n",
    "        self.model_name='ContentBased'\n",
    "        self.project_attributes=[\n",
    "            \"Project Title\",\n",
    "            \"Project Essay\",\n",
    "            \"Project Need Statement\"\n",
    "        ]\n",
    "        self.lspace=40\n",
    "\n",
    "    def build_project_profiles(self):\n",
    "        '''Text vectorizes all the projects'''\n",
    "        num_projects=self.projects.shape[0]\n",
    "        print('-> Building {} project profiles...'.\n",
    "              format(num_projects).ljust(self.lspace),end='')\n",
    "        start=time.time()\n",
    "        text_corpus=''\n",
    "        for attribute in self.project_attributes:\n",
    "            self.projects[attribute]=self.projects[attribute].astype(str)\n",
    "            self.projects[attribute].fillna('',inplace=True)\n",
    "            text_corpus+=' '+self.projects[attribute]\n",
    "        self.vectorizer=TfidfVectorizer(\n",
    "            strip_accents='unicode',\n",
    "            analyzer='word',\n",
    "            lowercase=True,\n",
    "            stop_words='english',\n",
    "            max_df=0.9,\n",
    "            token_pattern=r'(?u)\\b[A-Za-z]+\\b'\n",
    "        )\n",
    "        project_profiles=self.vectorizer.fit_transform(text_corpus)\n",
    "        end=time.time()\n",
    "        print('[{:.2f}s]'.format(end-start))\n",
    "        return project_profiles\n",
    "    \n",
    "    def build_donor_profiles(self,donor_ids):\n",
    "        '''\n",
    "        Builds the donor profiles based on the weighted average \n",
    "        of project profile they donated to and the logarthimic \n",
    "        of their donation amounts.\n",
    "        '''\n",
    "        project_ids=self.projects.index.to_list()\n",
    "        print('-> Building {} donor profiles...'.\n",
    "              format(len(donor_ids)).ljust(self.lspace))\n",
    "        donor_profiles=[]\n",
    "        for donor_id in tqdm_notebook(donor_ids):\n",
    "            donor_projects=self.donations.loc[donor_id]\n",
    "            idx=[project_ids.index(project_id) for project_id in donor_projects.index]\n",
    "            project_profiles=self.project_profiles[idx]\n",
    "            log_amounts=donor_projects.values\n",
    "            donor_profile=np.sum(project_profiles.multiply(log_amounts),axis=0)/(np.sum(log_amounts)+1)\n",
    "            donor_profile=sparse.csr_matrix(normalize(donor_profile))\n",
    "            donor_profiles.append(donor_profile)\n",
    "        donor_profiles=sparse.vstack(donor_profiles)        \n",
    "        return donor_profiles\n",
    "        \n",
    "    def fit(self,projects,donations,save_to='models'):\n",
    "        '''\n",
    "        Builds the donor profiles along with its donor id \n",
    "        in a pickle file.\n",
    "        '''\n",
    "        self.projects=projects\n",
    "        self.donations=donations\n",
    "        donor_ids=self.donations.index.get_level_values(0).unique()\n",
    "        num_donors=len(donor_ids)\n",
    "        filename=self.model_name+'{}.pickle'.format(num_donors)\n",
    "        model_filepath=os.path.join(save_to,filename)\n",
    "        if not os.path.exists(save_to):\n",
    "            os.makedirs(save_to)    \n",
    "        if os.path.isfile(model_filepath):\n",
    "            model=pickle.load(open(model_filepath,\"rb\"))\n",
    "            self.vectorizer=model[0]\n",
    "            self.donor_ids=model[0]\n",
    "            self.donor_profiles=model[0]\n",
    "            print('-> Model loaded from {}'.format(model_filepath))\n",
    "        else:\n",
    "            self.project_profiles=self.build_project_profiles()\n",
    "            self.donor_profiles=self.build_donor_profiles(donor_ids)\n",
    "            model=(self.vectorizer,donor_ids,self.donor_profiles)\n",
    "            pickle.dump(model,open(model_filepath,\"wb\"))   \n",
    "            print('-> Model saved to {}'.format(model_filepath))\n",
    "        \n",
    "    def predict(self,new_project):\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training\n",
    "Let's take a look at few of donor profiles which based on their past donations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Building 33586 project profiles...   [9.23s]\n",
      "-> Building 31928 donor profiles...     \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70faa5d86e834b43b9aecd2dc7599aae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=31928.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-> Model saved to models\\ContentBased31928.pickle\n"
     ]
    }
   ],
   "source": [
    "cbr=ContentBasedRecommender()\n",
    "cbr.fit(projects,donations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
